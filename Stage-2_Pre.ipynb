{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 获取抠图后的视频",
   "id": "c4250d96d4a87bd1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T21:17:17.660397Z",
     "start_time": "2025-06-23T21:16:52.950076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# video_dir = Path(\"./dataset/train\")\n",
    "video_dir = Path(\"./dataset/val\")\n",
    "mask_dir = Path(\"./dataset/gt\")\n",
    "save_dir = Path(\"./dataset/masked\")\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "video_files = list(video_dir.glob(\"*.mp4\"))\n",
    "\n",
    "def process_video(video_path, mask_path, save_path):\n",
    "    try:\n",
    "        mask = np.load(mask_path)  # (T, H, W)\n",
    "        T, H, W = mask.shape\n",
    "\n",
    "        cap = cv2.VideoCapture(str(video_path))\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        assert frame_count == T, (\n",
    "            f\"帧数不一致: video({frame_count}) vs mask({T}) [{video_path.name}]\"\n",
    "        )\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "        out = cv2.VideoWriter(str(save_path), fourcc, fps, (W, H))\n",
    "\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        for t in range(T):\n",
    "            ok, frame = cap.read()\n",
    "            if not ok:\n",
    "                raise RuntimeError(f\"读取第 {t} 帧失败: {video_path.name}\")\n",
    "            m = mask[t].astype(bool)\n",
    "            black_frame = frame.copy()\n",
    "            black_frame[~m] = 0\n",
    "            out.write(black_frame)\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        return str(save_path)\n",
    "    except Exception as e:\n",
    "        return f\"❌ {video_path.name}: {e}\"\n",
    "\n",
    "# 多线程处理\n",
    "max_workers = min(8, len(video_files))  # 可根据CPU数量调整\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    tasks = []\n",
    "    for video_path in video_files:\n",
    "        video_name = video_path.stem\n",
    "        mask_path = mask_dir / f\"{video_name}.npy\"\n",
    "        save_path = save_dir / f\"{video_name}.mp4\"\n",
    "        if not mask_path.exists():\n",
    "            print(f\"❌ 缺少 mask: {mask_path}, 跳过 {video_path.name}\")\n",
    "            continue\n",
    "        tasks.append(executor.submit(process_video, video_path, mask_path, save_path))\n",
    "\n",
    "    for f in tqdm(as_completed(tasks), total=len(tasks), desc=\"批量处理视频\"):\n",
    "        result = f.result()\n",
    "        # 可以选择输出异常或保存成功的路径\n",
    "        if isinstance(result, str) and result.startswith(\"❌\"):\n",
    "            print(result)\n",
    "\n",
    "print(\"✅ 全部处理完成！\")\n"
   ],
   "id": "68374afac276f1d1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "批量处理视频: 100%|██████████| 657/657 [00:24<00:00, 26.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 全部处理完成！\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 生成masked视频描述",
   "id": "a8a36c071d7078a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T17:02:17.610660Z",
     "start_time": "2025-06-24T17:01:40.043662Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %% 推理函数\n",
    "import numpy as np\n",
    "import cv2, torch\n",
    "from pathlib import Path\n",
    "import PIL.Image as Image\n",
    "from transformers import AutoProcessor, Qwen2_5_VLForConditionalGeneration\n",
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-32B-Instruct\")\n",
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-VL-32B-Instruct\",\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    ")\n"
   ],
   "id": "881d714e8e8009f9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/18 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8a3796157399427da1de9560165759b0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T17:02:17.904767Z",
     "start_time": "2025-06-24T17:02:17.899531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------- 辅助工具 ----------\n",
    "def is_pure_black(frame: np.ndarray, thr: int = 1) -> bool:\n",
    "    \"\"\"判断单帧是否近似纯黑。thr 越大越宽松。\"\"\"\n",
    "    return np.max(frame) < thr\n",
    "\n",
    "def sample_frames(video_path: Path, num_frames: int = 8):\n",
    "    \"\"\"读取视频中所有帧并返回 PIL 图像列表。\"\"\"\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    frames = []\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frames.append(Image.fromarray(frame_rgb))\n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "def describe_video(video_path: Path, temperature: float = 0.1, fps: float = 24.0):\n",
    "    \"\"\"返回四元组字符串，如 [是][一个人][在奔跑][从视频左下角跑到了右上角]\"\"\"\n",
    "    frames = sample_frames(video_path)\n",
    "    # 纯黑快速判断（提高效率）\n",
    "    if all(is_pure_black(np.array(f)) for f in frames):\n",
    "        return \"没有异常\"\n",
    "    else:\n",
    "        return \"有异常\"\n",
    "\n",
    "    # 构建 messages\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"video\",\n",
    "                    \"video\": str(video_path),\n",
    "                    \"fps\": fps,\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"非黑色区域中有什么？简洁回答目标名称（如：一个骑自行车的人，一辆汽车，一群人在打闹...）\",\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # 构建输入文本（包含 Chat 模板）\n",
    "    text = processor.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    # 处理视频与文本输入\n",
    "    image_inputs, video_inputs, video_kwargs = process_vision_info(messages, return_video_kwargs=True)\n",
    "    inputs = processor(\n",
    "        text=[text],\n",
    "        images=image_inputs,\n",
    "        videos=video_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "        **video_kwargs,\n",
    "    )\n",
    "    inputs = inputs.to(device)\n",
    "\n",
    "    # 推理\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=512, temperature=temperature)\n",
    "\n",
    "    # 去除输入 prompt 部分的 token（如你希望保留完整输出也可以不裁剪）\n",
    "    generated_ids_trimmed = [\n",
    "        out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "\n",
    "    # 解码输出文本\n",
    "    output_text = processor.batch_decode(\n",
    "        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "    )[0].strip()\n",
    "\n",
    "    return output_text\n"
   ],
   "id": "6ed3d0549170810b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T17:04:43.678274Z",
     "start_time": "2025-06-24T17:02:18.176052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "masked_dir = Path(\"./dataset/masked\")\n",
    "save_csv = Path(\"dataset/labels.csv\")\n",
    "\n",
    "video_paths = list(masked_dir.glob(\"*.mp4\"))\n",
    "results = []\n",
    "\n",
    "for i, vp in tqdm(enumerate(video_paths, 1)):\n",
    "    video_name = vp.name\n",
    "    # print(f\"\\n正在处理第{i}/{len(video_paths)}个视频：{video_name}\")\n",
    "    try:\n",
    "        desc = describe_video(vp)\n",
    "    except Exception as e:\n",
    "        desc = f\"❌{e}\"\n",
    "    # print(f\"描述结果：{desc}\")\n",
    "\n",
    "    # 追加到结果\n",
    "    results.append({\"video\": video_name, \"description\": desc})\n",
    "\n",
    "    # 实时保存，防止中断丢数据\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(save_csv, index=False, encoding=\"utf-8-sig\")\n",
    "    # print(f\"✅ 已保存进度到 {save_csv}\")\n",
    "\n",
    "# 最终显示\n",
    "df = pd.DataFrame(results)\n",
    "print(df.head())\n"
   ],
   "id": "f300d785d7111a81",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3283it [02:25, 22.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 video description\n",
      "0  01_0014-000_023.mp4        没有异常\n",
      "1  01_0014-012_035.mp4        没有异常\n",
      "2  01_0014-024_047.mp4        没有异常\n",
      "3  01_0014-036_059.mp4        没有异常\n",
      "4  01_0014-048_071.mp4        没有异常\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e2e52126ce2782d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
